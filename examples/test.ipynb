{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">BCFind testing</h1>\n",
    "This notebook gives an example on how to test BCFind by using modules and classes provided by the library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from bcfind.localizers import BlobDoG\n",
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.set_visible_devices(gpus[-1], \"GPU\")\n",
    "tf.config.experimental.set_memory_growth(gpus[-1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_my_data = \"My_Data\"\n",
    "path_to_my_exp = \"My_Exp\"\n",
    "\n",
    "max_input_shape = (160, 480, 480)\n",
    "voxel_resolution = (2, 0.65, 0.65)\n",
    "exclude_border = (3, 9, 9)\n",
    "max_match_dist = 10\n",
    "\n",
    "tiff_dir = f\"{path_to_my_data}/Tiff_files/Test\"\n",
    "gt_dir = f\"{path_to_my_data}/GT_files/Test\"\n",
    "\n",
    "tf_checkpoint_dir = f\"{path_to_my_exp}/UNet_checkpoints\"\n",
    "dog_checkpoint_dir = f\"{path_to_my_exp}/DoG_checkpoints\"\n",
    "\n",
    "lmdb_dir = f\"{path_to_my_exp}/UNet_test_pred_lmdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_files = [f\"{tiff_dir}/{fname}\" for fname in os.listdir(tiff_dir)]\n",
    "gt_files = [f\"{gt_dir}/{fname}.marker\" for fname in os.listdir(tiff_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    f\"{tf_checkpoint_dir}/model.tf\",\n",
    "    compile=False,\n",
    ")\n",
    "model.build((None, None, None, None, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = {\n",
    "    \"clip\": \"bit\",\n",
    "    \"clip_value\": 15,  # clip can be ['bit', 'constant', 'quantile', None]\n",
    "    \"center\": None,\n",
    "    \"center_value\": None,  # center can be one of ['constant', 'min', 'mean', null]\n",
    "    \"scale\": \"bit\",\n",
    "    \"scale_value\": 15,  # scale can be one of ['constant', 'bit', 'max', 'std', null]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bcfind.utils.models import predict\n",
    "from bcfind.utils.data import get_input_tf, get_gt_as_numpy\n",
    "\n",
    "\n",
    "n = len(tiff_files)\n",
    "nbytes = np.prod(max_input_shape) * 1  # 4 bytes for float32: 1 byte for uint8\n",
    "db = lmdb.open(lmdb_dir, map_size=n * nbytes * 10)\n",
    "\n",
    "# UNet predictions\n",
    "print(f\"Saving U-Net predictions in {lmdb_dir}\")\n",
    "with db.begin(write=True) as fx:\n",
    "    for i, tiff_file in enumerate(tiff_files):\n",
    "        print(f\"\\nUnet prediction on file {i+1}/{len(tiff_files)}\")\n",
    "\n",
    "        x = get_input_tf(tiff_file, **preprocessing)\n",
    "        pred = predict(x, model).numpy()\n",
    "        pred = tf.sigmoid(tf.squeeze(pred)).numpy()\n",
    "        pred = (pred * 255).astype(\"uint8\")\n",
    "\n",
    "        fname = tiff_file.split(\"/\")[-1]\n",
    "        fx.put(key=fname.encode(), value=pickle.dumps(pred))\n",
    "\n",
    "db.close()\n",
    "dog_inputs = lmdb.open(lmdb_dir, readonly=True)\n",
    "\n",
    "# True cell coordinates\n",
    "dog_targets = []\n",
    "for marker_file in gt_files:\n",
    "    print(f\"Loading file {marker_file}\")\n",
    "    y = get_gt_as_numpy(marker_file)\n",
    "    dog_targets.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bcfind.utils.base import evaluate_df\n",
    "\n",
    "\n",
    "dog = BlobDoG(3, voxel_resolution, exclude_border)\n",
    "dog_par = json.load(open(f\"{dog_checkpoint_dir}/BlobDoG_parameters.json\", \"r\"))\n",
    "dog.set_parameters(dog_par)\n",
    "print(f\"Best parameters found for DoG: {dog_par}\")\n",
    "\n",
    "with dog_inputs.begin() as fx:\n",
    "    db_iterator = fx.cursor()\n",
    "    res = []\n",
    "    for i, (fname, x) in enumerate(db_iterator):\n",
    "        pred = dog.predict_and_evaluate(x, dog_targets[i], max_match_dist, \"counts\")\n",
    "\n",
    "        pred[\"f1\"] = pred[\"TP\"] / (pred[\"TP\"] + 0.5 * (pred[\"FP\"] + pred[\"FN\"]))\n",
    "        pred[\"file\"] = fname.decode()\n",
    "        res.append(pred)\n",
    "dog_inputs.close()\n",
    "\n",
    "res = pd.concat(res)\n",
    "res.to_csv(f\"{path_to_my_exp}/Test_eval.csv\", index=False)\n",
    "perf = evaluate_df(res)\n",
    "\n",
    "print(f\"\\nTest-set evaluated with {perf}\")\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
